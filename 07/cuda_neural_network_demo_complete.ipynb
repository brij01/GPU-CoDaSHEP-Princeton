{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CUDA Neural Network Demo - Example from current production code LHCb HLT1 trigger\n",
        "\n",
        "The repository demonstrates a GPU-accelerated single-layer fully connected neural network implementation specifically designed for high-performance inference on NVIDIA GPUs.\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- **GPU-accelerated inference**: Neural network evaluation runs entirely on GPU using CUDA\n",
        "- **Template-based design**: Compile-time configuration of input size and hidden nodes\n",
        "- **Optimized CUDA kernels**: Uses loop unrolling and fast math operations for performance\n",
        "- **Random model generation**: Utility to generate random weights and biases for testing\n",
        "- **Comprehensive testing**: Includes validation and statistics\n",
        "\n",
        "## Neural Network Architecture\n",
        "\n",
        "The implementation features a single-layer fully connected neural network with:\n",
        "- **Input Layer**: Configurable size (template parameter)\n",
        "- **Hidden Layer**: Single fully connected layer with ReLU activation\n",
        "- **Output Layer**: Single neuron with sigmoid activation (0-1 output range)\n",
        "- **Data preprocessing**: Input normalization using mean and standard deviation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "\n",
        "1. [Introduction and Architecture](#1-introduction-and-architecture)\n",
        "2. [Project Structure](#2-project-structure)\n",
        "3. [Core Implementation - demo.cu](#3-core-implementation---democu)\n",
        "4. [Test Program - main.cu](#4-test-program---maincu)\n",
        "5. [Random Model Generator](#5-random-model-generator)\n",
        "6. [Build System Configuration](#6-build-system-configuration)\n",
        "7. [Mock Dependencies](#7-mock-dependencies)\n",
        "8. [JSON Model Format](#8-json-model-format)\n",
        "9. [Compilation and Usage](#9-compilation-and-usage)\n",
        "10. [Performance Analysis](#10-performance-analysis)\n",
        "11. [Allen Framework Background](#11-allen-framework-background)\n",
        "12. [Complete Example Workflow](#12-complete-example-workflow)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Introduction and Architecture\n",
        "\n",
        "### What is a Neural Network?\n",
        "\n",
        "A neural network is a computational model inspired by biological neural networks. It consists of interconnected nodes (neurons) organized in layers that transform input data to produce desired outputs through learned parameters (weights and biases).\n",
        "\n",
        "### GPU Acceleration for Neural Networks\n",
        "\n",
        "### Architecture Overview\n",
        "\n",
        "```\n",
        "Input Layer (4 neurons)\n",
        "    ↓ (normalization: (x - mean) / std)\n",
        "    ↓\n",
        "Hidden Layer (8 neurons, ReLU activation)\n",
        "    ↓ (fully connected weights1[8][4] + bias1[8])\n",
        "    ↓\n",
        "Output Layer (1 neuron, Sigmoid activation)\n",
        "    ↓ (weights2[8] + bias2)\n",
        "    ↓\n",
        "Final Output (0.0 to 1.0)\n",
        "```\n",
        "\n",
        "### Mathematical Formulation\n",
        "\n",
        "The forward pass computes:\n",
        "\n",
        "1. **Input Normalization**: `x_norm[i] = (x[i] - mean[i]) / std[i]`\n",
        "2. **Hidden Layer**: `h[j] = ReLU(Σ(x_norm[i] * weights1[j][i]) + bias1[j])`\n",
        "3. **Output Layer**: `output = Sigmoid(Σ(h[j] * weights2[j]) + bias2)`\n",
        "\n",
        "Where:\n",
        "- `ReLU(x) = max(0, x)`\n",
        "- `Sigmoid(x) = 1 / (1 + exp(-x))`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Project Structure\n",
        "\n",
        "The repository contains the following files:\n",
        "\n",
        "```\n",
        "gpu-demo/\n",
        "├── demo.cu                 # Main neural network implementation\n",
        "├── main.cu                 # Test program with CUDA kernel\n",
        "├── nn_gen/\n",
        "│   └── json_generator.cpp  # Utility to generate random model parameters\n",
        "├── mock_dependencies.h     # Mock implementations for Allen framework\n",
        "├── MVAModelsManager.h      # Header with framework includes\n",
        "├── CMakeLists.txt         # Build system configuration\n",
        "├── .gitignore            # Git ignore patterns\n",
        "└── README.md             # Project documentation\n",
        "```\n",
        "\n",
        "### File Descriptions\n",
        "\n",
        "| File | Purpose | Language |\n",
        "|------|---------|----------|\n",
        "| `demo.cu` | Core neural network implementation with CUDA kernels | CUDA C++ |\n",
        "| `main.cu` | Test harness and example usage | CUDA C++ |\n",
        "| `json_generator.cpp` | Random model parameter generation | C++ |\n",
        "| `mock_dependencies.h` | Allen framework compatibility layer | C++ |\n",
        "| `MVAModelsManager.h` | Framework integration headers | C++ |\n",
        "| `CMakeLists.txt` | CMake build configuration | CMake |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Core Implementation - demo.cu\n",
        "\n",
        "The `demo.cu` file contains the heart of the neural network implementation. Let's examine each component:\n",
        "\n",
        "### 3.1 Headers and Namespace\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// Main neural network implementation from demo.cu\n",
        "#pragma once\n",
        "#include \"MVAModelsManager.h\"\n",
        "#include <nlohmann/json.hpp>\n",
        "\n",
        "namespace Allen::MVAModels {\n",
        "\n",
        "// Structure to hold single layer neural network data\n",
        "struct SingleLayerData {\n",
        "    std::vector<float> mean;\n",
        "    std::vector<float> std;\n",
        "    std::vector<std::vector<float>> weights1;\n",
        "    std::vector<float> fweights1;  // Flattened weights1\n",
        "    std::vector<float> bias1;\n",
        "    std::vector<float> weights2;\n",
        "    float bias2;\n",
        "};\n",
        "\n",
        "// Function to read JSON model parameters\n",
        "inline SingleLayerData readSingleLayerJSON(std::string full_path) {\n",
        "    SingleLayerData to_copy;\n",
        "\n",
        "    nlohmann::json j;\n",
        "    {\n",
        "        std::ifstream i(full_path);\n",
        "        j = nlohmann::json::parse(i);\n",
        "    }\n",
        "\n",
        "    // Parse JSON fields\n",
        "    using array1d_t = std::vector<float>;\n",
        "    using array2d_t = std::vector<std::vector<float>>;\n",
        "\n",
        "    to_copy.mean = j.at(\"mean\").get<array1d_t>();\n",
        "    to_copy.std = j.at(\"std\").get<array1d_t>();\n",
        "    to_copy.weights1 = j.at(\"weights1\").get<array2d_t>();\n",
        "    to_copy.bias1 = j.at(\"bias1\").get<array1d_t>();\n",
        "    to_copy.weights2 = j.at(\"weights2\").get<array1d_t>();\n",
        "    to_copy.bias2 = j.at(\"bias2\").get<float>();\n",
        "\n",
        "    // Sanity checks\n",
        "    assert(to_copy.mean.size() == j.at(\"num_input\").get<int>());\n",
        "    assert(to_copy.std.size() == j.at(\"num_input\").get<int>());\n",
        "    assert(to_copy.weights1.size() == j.at(\"num_node\").get<int>() && \n",
        "           to_copy.weights1.front().size() == j.at(\"num_input\").get<int>());\n",
        "    assert(to_copy.bias1.size() == j.at(\"num_node\").get<int>());\n",
        "    assert(to_copy.weights2.size() == j.at(\"num_node\").get<int>());\n",
        "\n",
        "    // Flatten 2D weights array for GPU transfer\n",
        "    for (const auto& innerVec : to_copy.weights1) {\n",
        "        to_copy.fweights1.insert(to_copy.fweights1.end(), \n",
        "                                innerVec.begin(), innerVec.end());\n",
        "    }\n",
        "\n",
        "    return to_copy;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Device Neural Network Structure\n",
        "\n",
        "The template-based device structure allows compile-time optimization:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// Template-based device neural network structure\n",
        "template <unsigned num_input, unsigned num_node>\n",
        "struct DeviceSingleLayerFCNN {\n",
        "    constexpr static unsigned nInput = num_input;\n",
        "    constexpr static unsigned nNode = num_node;\n",
        "\n",
        "    // Data preprocessing parameters\n",
        "    float mean[nInput];\n",
        "    float std[nInput];\n",
        "\n",
        "    // Model parameters\n",
        "    float weights1[nNode][nInput];\n",
        "    float bias1[nNode];\n",
        "    float weights2[nNode];\n",
        "    float bias2;\n",
        "\n",
        "    // Main evaluation function (defined later)\n",
        "    __device__ inline float evaluate(float* input) const;\n",
        "};"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Host Neural Network Class\n",
        "\n",
        "The host class manages GPU memory and model loading:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// Host neural network class template\n",
        "template <unsigned num_input, unsigned num_node>\n",
        "struct SingleLayerFCNN : public MVAModelBase {\n",
        "    using DeviceType = DeviceSingleLayerFCNN<num_input, num_node>;\n",
        "\n",
        "    SingleLayerFCNN(std::string name, std::string path) \n",
        "        : MVAModelBase(name, path) {\n",
        "        m_device_pointer = nullptr;\n",
        "    }\n",
        "\n",
        "    const DeviceType* getDevicePointer() const {\n",
        "        return m_device_pointer;\n",
        "    }\n",
        "\n",
        "    void readData(std::string parameters_path) override {\n",
        "        auto data_to_copy = readSingleLayerJSON(parameters_path + m_path);\n",
        "\n",
        "        // Allocate GPU memory\n",
        "        Allen::malloc((void**)&m_device_pointer, sizeof(DeviceType));\n",
        "\n",
        "        // Calculate memory sizes\n",
        "        constexpr auto size_mean = DeviceType::nInput * sizeof(float);\n",
        "        constexpr auto size_std = DeviceType::nInput * sizeof(float);\n",
        "        constexpr auto size_weights1 = (DeviceType::nNode * DeviceType::nInput) * sizeof(float);\n",
        "        constexpr auto size_bias1 = DeviceType::nNode * sizeof(float);\n",
        "        constexpr auto size_weights2 = DeviceType::nNode * sizeof(float);\n",
        "        constexpr auto size_bias2 = sizeof(float);\n",
        "\n",
        "        // Copy data to GPU\n",
        "        Allen::memcpy(m_device_pointer->mean, data_to_copy.mean.data(), \n",
        "                     size_mean, Allen::memcpyHostToDevice);\n",
        "        Allen::memcpy(m_device_pointer->std, data_to_copy.std.data(), \n",
        "                     size_std, Allen::memcpyHostToDevice);\n",
        "        Allen::memcpy(m_device_pointer->weights1, data_to_copy.fweights1.data(), \n",
        "                     size_weights1, Allen::memcpyHostToDevice);\n",
        "        Allen::memcpy(m_device_pointer->bias1, data_to_copy.bias1.data(), \n",
        "                     size_bias1, Allen::memcpyHostToDevice);\n",
        "        Allen::memcpy(m_device_pointer->weights2, data_to_copy.weights2.data(), \n",
        "                     size_weights2, Allen::memcpyHostToDevice);\n",
        "        Allen::memcpy(&m_device_pointer->bias2, &data_to_copy.bias2, \n",
        "                     size_bias2, Allen::memcpyHostToDevice);\n",
        "    }\n",
        "\n",
        "private:\n",
        "    DeviceType* m_device_pointer;\n",
        "};"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Activation Functions\n",
        "\n",
        "The implementation includes optimized CUDA device functions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// Activation functions namespace\n",
        "namespace ActivateFunction {\n",
        "    // Rectified Linear Unit\n",
        "    __device__ inline float relu(const float x) {\n",
        "        return x > 0 ? x : 0;\n",
        "    }\n",
        "\n",
        "    // Sigmoid activation function\n",
        "    __device__ inline float sigmoid(const float x) {\n",
        "        return 1.0f / (1.0f + __expf(-x));\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5 Main Evaluation Function\n",
        "\n",
        "The heart of the neural network - the forward pass implementation:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// Template specialization for the evaluate function\n",
        "template <unsigned num_input, unsigned num_node>\n",
        "__device__ inline float Allen::MVAModels::DeviceSingleLayerFCNN<num_input, num_node>::evaluate(float* input) const {\n",
        "    using ModelType = Allen::MVAModels::DeviceSingleLayerFCNN<num_input, num_node>;\n",
        "\n",
        "    // Data preprocessing - normalize inputs\n",
        "#if (defined(TARGET_DEVICE_CUDA) && defined(__CUDACC__))\n",
        "#pragma unroll\n",
        "#endif\n",
        "    for (unsigned i = 0; i < ModelType::nInput; i++) {\n",
        "        input[i] = (input[i] - mean[i]) / std[i];\n",
        "    }\n",
        "\n",
        "    // Initialize hidden layer activations\n",
        "    float h1[ModelType::nNode] = {0.f};\n",
        "\n",
        "    // First layer computation with ReLU activation\n",
        "#if (defined(TARGET_DEVICE_CUDA) && defined(__CUDACC__))\n",
        "#pragma unroll\n",
        "#endif\n",
        "    for (unsigned i = 0; i < ModelType::nNode; i++) {\n",
        "#if (defined(TARGET_DEVICE_CUDA) && defined(__CUDACC__))\n",
        "#pragma unroll\n",
        "#endif\n",
        "        for (unsigned j = 0; j < ModelType::nInput; j++) {\n",
        "            h1[i] += input[j] * weights1[i][j];\n",
        "        }\n",
        "        h1[i] = ActivateFunction::relu(h1[i] + bias1[i]);\n",
        "    }\n",
        "\n",
        "    // Output layer computation\n",
        "    float output = 0.f;\n",
        "#if (defined(TARGET_DEVICE_CUDA) && defined(__CUDACC__))\n",
        "#pragma unroll\n",
        "#endif\n",
        "    for (unsigned i = 0; i < ModelType::nNode; i++) {\n",
        "        output += h1[i] * weights2[i];\n",
        "    }\n",
        "\n",
        "    // Apply sigmoid activation to final output\n",
        "    output = ActivateFunction::sigmoid(output + bias2);\n",
        "\n",
        "    return output;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Test Program - main.cu\n",
        "\n",
        "The `main.cu` file demonstrates how to use the neural network implementation with a complete CUDA kernel test harness.\n",
        "\n",
        "### 4.1 CUDA Kernel for Neural Network Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#include \"mock_dependencies.h\"\n",
        "#include \"demo.cu\"\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <random>\n",
        "#include <iomanip>\n",
        "#include <algorithm>\n",
        "#include <numeric>\n",
        "\n",
        "// CUDA kernel to test neural network evaluation\n",
        "template <unsigned num_input, unsigned num_node>\n",
        "__global__ void test_neural_network_kernel(\n",
        "    const Allen::MVAModels::DeviceSingleLayerFCNN<num_input, num_node>* model,\n",
        "    float* input_data,\n",
        "    float* output_data,\n",
        "    int num_tests)\n",
        "{\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < num_tests) {\n",
        "        // Each thread processes one test case\n",
        "        float local_input[num_input];\n",
        "        for (int i = 0; i < num_input; i++) {\n",
        "            local_input[i] = input_data[idx * num_input + i];\n",
        "        }\n",
        "\n",
        "        // Evaluate the neural network\n",
        "        output_data[idx] = model->evaluate(local_input);\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Host Test Function\n",
        "\n",
        "The comprehensive test function that orchestrates the entire evaluation process:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// Host function to test neural network evaluation\n",
        "void test_neural_network_evaluation(const std::string& json_filepath) {\n",
        "    constexpr unsigned num_input = 4;\n",
        "    constexpr unsigned num_node = 8;\n",
        "    constexpr int num_tests = 10;\n",
        "\n",
        "    std::cout << \"\\n=== Neural Network Evaluation Test ===\" << std::endl;\n",
        "    std::cout << \"Network configuration:\" << std::endl;\n",
        "    std::cout << \"- Input size: \" << num_input << std::endl;\n",
        "    std::cout << \"- Hidden nodes: \" << num_node << std::endl;\n",
        "    std::cout << \"- Number of test cases: \" << num_tests << std::endl;\n",
        "\n",
        "    // Parse file path\n",
        "    std::string path, filename;\n",
        "    size_t last_slash_idx = json_filepath.find_last_of(\"/\");\n",
        "    if (std::string::npos != last_slash_idx) {\n",
        "        path = json_filepath.substr(0, last_slash_idx + 1);\n",
        "        filename = json_filepath.substr(last_slash_idx + 1);\n",
        "    } else {\n",
        "        path = \"./\";\n",
        "        filename = json_filepath;\n",
        "    }\n",
        "\n",
        "    // Create and initialize the model\n",
        "    Allen::MVAModels::SingleLayerFCNN<num_input, num_node> model(\"test_model\", filename);\n",
        "\n",
        "    try {\n",
        "        // Load model data\n",
        "        model.readData(path);\n",
        "        std::cout << \"✓ Model loaded successfully\" << std::endl;\n",
        "    } catch (const std::exception& e) {\n",
        "        std::cout << \"✗ Error loading model: \" << e.what() << std::endl;\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    // Generate random test input data\n",
        "    std::random_device rd;\n",
        "    std::mt19937 gen(rd());\n",
        "    std::uniform_real_distribution<float> dis(-2.0f, 2.0f);\n",
        "\n",
        "    std::vector<float> host_input(num_tests * num_input);\n",
        "    std::vector<float> host_output(num_tests);\n",
        "\n",
        "    std::cout << \"\\nGenerating random test inputs...\" << std::endl;\n",
        "    for (int i = 0; i < num_tests * num_input; i++) {\n",
        "        host_input[i] = dis(gen);\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    float* device_input;\n",
        "    float* device_output;\n",
        "\n",
        "    cudaMalloc(&device_input, num_tests * num_input * sizeof(float));\n",
        "    cudaMalloc(&device_output, num_tests * sizeof(float));\n",
        "\n",
        "    // Copy input data to device\n",
        "    cudaMemcpy(device_input, host_input.data(), \n",
        "               num_tests * num_input * sizeof(float), \n",
        "               cudaMemcpyHostToDevice);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Kernel Launch and Results Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    // Launch kernel\n",
        "    int block_size = 256;\n",
        "    int grid_size = (num_tests + block_size - 1) / block_size;\n",
        "\n",
        "    std::cout << \"Launching CUDA kernel...\" << std::endl;\n",
        "    std::cout << \"Grid size: \" << grid_size << \", Block size: \" << block_size << std::endl;\n",
        "\n",
        "    test_neural_network_kernel<<<grid_size, block_size>>>(\n",
        "        model.getDevicePointer(), device_input, device_output, num_tests);\n",
        "\n",
        "    // Check for kernel launch errors\n",
        "    cudaError_t kernel_error = cudaGetLastError();\n",
        "    if (kernel_error != cudaSuccess) {\n",
        "        std::cout << \"✗ CUDA kernel launch error: \" << cudaGetErrorString(kernel_error) << std::endl;\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    // Wait for kernel to complete\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Copy results back to host\n",
        "    cudaMemcpy(host_output.data(), device_output, \n",
        "               num_tests * sizeof(float), \n",
        "               cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Display results\n",
        "    std::cout << \"\\n=== Test Results ===\" << std::endl;\n",
        "    std::cout << std::fixed << std::setprecision(6);\n",
        "\n",
        "    for (int i = 0; i < num_tests; i++) {\n",
        "        std::cout << \"Test \" << std::setw(2) << (i + 1) << \": \";\n",
        "        std::cout << \"Input [\";\n",
        "        for (int j = 0; j < num_input; j++) {\n",
        "            std::cout << std::setw(8) << host_input[i * num_input + j];\n",
        "            if (j < num_input - 1) std::cout << \", \";\n",
        "        }\n",
        "        std::cout << \"] -> Output: \" << std::setw(8) << host_output[i] << std::endl;\n",
        "    }\n",
        "\n",
        "    // Validate outputs (sigmoid should produce values between 0 and 1)\n",
        "    bool all_valid = true;\n",
        "    for (int i = 0; i < num_tests; i++) {\n",
        "        if (host_output[i] < 0.0f || host_output[i] > 1.0f) {\n",
        "            all_valid = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    std::cout << \"\\n=== Validation ===\" << std::endl;\n",
        "    if (all_valid) {\n",
        "        std::cout << \"✓ All outputs are in valid range [0, 1] (sigmoid activation)\" << std::endl;\n",
        "    } else {\n",
        "        std::cout << \"✗ Some outputs are outside valid range [0, 1]\" << std::endl;\n",
        "    }\n",
        "\n",
        "    // Calculate statistics\n",
        "    float min_output = *std::min_element(host_output.begin(), host_output.end());\n",
        "    float max_output = *std::max_element(host_output.begin(), host_output.end());\n",
        "    float avg_output = std::accumulate(host_output.begin(), host_output.end(), 0.0f) / num_tests;\n",
        "\n",
        "    std::cout << \"Output statistics:\" << std::endl;\n",
        "    std::cout << \"- Min: \" << min_output << std::endl;\n",
        "    std::cout << \"- Max: \" << max_output << std::endl;\n",
        "    std::cout << \"- Average: \" << avg_output << std::endl;\n",
        "\n",
        "    // Clean up\n",
        "    cudaFree(device_input);\n",
        "    cudaFree(device_output);\n",
        "\n",
        "    std::cout << \"\\n✓ Test completed successfully!\" << std::endl;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Main Function\n",
        "\n",
        "The entry point that handles command-line arguments and GPU detection:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "int main(int argc, char* argv[]) {\n",
        "    std::cout << \"CUDA Neural Network Demo\" << std::endl;\n",
        "    std::cout << \"========================\" << std::endl;\n",
        "\n",
        "    if (argc < 2) {\n",
        "        std::cerr << \"Usage: \" << argv[0] << \" <path_to_model.json>\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Check CUDA device\n",
        "    int device_count;\n",
        "    cudaGetDeviceCount(&device_count);\n",
        "\n",
        "    if (device_count == 0) {\n",
        "        std::cout << \"✗ No CUDA devices found!\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    cudaDeviceProp prop;\n",
        "    cudaGetDeviceProperties(&prop, 0);\n",
        "    std::cout << \"Using CUDA device: \" << prop.name << std::endl;\n",
        "    std::cout << \"Compute capability: \" << prop.major << \".\" << prop.minor << std::endl;\n",
        "\n",
        "    // Run the neural network test\n",
        "    test_neural_network_evaluation(argv[1]);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Random Model Generator\n",
        "\n",
        "The `nn_gen/json_generator.cpp` file creates random neural network parameters for testing purposes.\n",
        "\n",
        "### 5.1 Generator Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#include <iostream>\n",
        "#include <fstream>\n",
        "#include <vector>\n",
        "#include <random>\n",
        "#include <iomanip>\n",
        "#include <nlohmann/json.hpp>\n",
        "\n",
        "void generate_random_model(const std::string& filename, \n",
        "                          unsigned num_input, \n",
        "                          unsigned num_node,\n",
        "                          float weight_range = 1.0f, \n",
        "                          float bias_range = 0.5f) {\n",
        "\n",
        "    nlohmann::json j;\n",
        "\n",
        "    std::random_device rd;\n",
        "    std::mt19937 gen(rd());\n",
        "    std::uniform_real_distribution<float> weight_dist(-weight_range, weight_range);\n",
        "    std::uniform_real_distribution<float> bias_dist(-bias_range, bias_range);\n",
        "    std::uniform_real_distribution<float> norm_dist(0.1f, 2.0f); // For mean/std normalization\n",
        "\n",
        "    j[\"num_input\"] = num_input;\n",
        "    j[\"num_node\"] = num_node;\n",
        "\n",
        "    // Generate mean values for input normalization\n",
        "    std::vector<float> mean(num_input);\n",
        "    for (unsigned i = 0; i < num_input; i++) {\n",
        "        mean[i] = norm_dist(gen);\n",
        "    }\n",
        "    j[\"mean\"] = mean;\n",
        "\n",
        "    // Generate std values for input normalization  \n",
        "    std::vector<float> std_dev(num_input);\n",
        "    for (unsigned i = 0; i < num_input; i++) {\n",
        "        std_dev[i] = norm_dist(gen);\n",
        "    }\n",
        "    j[\"std\"] = std_dev;\n",
        "\n",
        "    // Generate weights1 (2D array: num_node x num_input)\n",
        "    std::vector<std::vector<float>> weights1(num_node, std::vector<float>(num_input));\n",
        "    for (unsigned i = 0; i < num_node; i++) {\n",
        "        for (unsigned j = 0; j < num_input; j++) {\n",
        "            weights1[i][j] = weight_dist(gen);\n",
        "        }\n",
        "    }\n",
        "    j[\"weights1\"] = weights1;\n",
        "\n",
        "    // Generate bias1 (hidden layer biases)\n",
        "    std::vector<float> bias1(num_node);\n",
        "    for (unsigned i = 0; i < num_node; i++) {\n",
        "        bias1[i] = bias_dist(gen);\n",
        "    }\n",
        "    j[\"bias1\"] = bias1;\n",
        "\n",
        "    // Generate weights2 (output layer weights)\n",
        "    std::vector<float> weights2(num_node);\n",
        "    for (unsigned i = 0; i < num_node; i++) {\n",
        "        weights2[i] = weight_dist(gen);\n",
        "    }\n",
        "    j[\"weights2\"] = weights2;\n",
        "\n",
        "    // Generate bias2 (output layer bias)\n",
        "    j[\"bias2\"] = bias_dist(gen);\n",
        "\n",
        "    // Write to file\n",
        "    std::ofstream file(filename);\n",
        "    file << std::setw(4) << j << std::endl;\n",
        "    file.close();\n",
        "\n",
        "    std::cout << \"Generated random model: \" << filename << std::endl;\n",
        "    std::cout << \"- Input size: \" << num_input << std::endl;\n",
        "    std::cout << \"- Hidden nodes: \" << num_node << std::endl;\n",
        "    std::cout << \"- Weight range: [-\" << weight_range << \", \" << weight_range << \"]\" << std::endl;\n",
        "    std::cout << \"- Bias range: [-\" << bias_range << \", \" << bias_range << \"]\" << std::endl;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Generator Main Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "int main(int argc, char* argv[]) {\n",
        "    unsigned num_input = 4;\n",
        "    unsigned num_node = 8;\n",
        "    std::string filename = \"random_model.json\";\n",
        "\n",
        "    if (argc > 1) num_input = std::stoi(argv[1]);\n",
        "    if (argc > 2) num_node = std::stoi(argv[2]);\n",
        "    if (argc > 3) filename = argv[3];\n",
        "\n",
        "    std::cout << \"Random Neural Network Model Generator\" << std::endl;\n",
        "    std::cout << \"====================================\" << std::endl;\n",
        "\n",
        "    generate_random_model(filename, num_input, num_node);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Build System Configuration\n",
        "\n",
        "The `CMakeLists.txt` file defines the build process using CMake.\n",
        "\n",
        "### 6.1 CMake Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cmake_minimum_required(VERSION 3.18)\n",
        "\n",
        "project(GpuDemoNN LANGUAGES CXX CUDA)\n",
        "\n",
        "# Find required packages\n",
        "find_package(nlohmann_json 3.2.0 REQUIRED)\n",
        "\n",
        "# Neural network test executable\n",
        "add_executable(neural_network_test main.cu demo.cu)\n",
        "target_link_libraries(neural_network_test PRIVATE nlohmann_json::nlohmann_json)\n",
        "set_target_properties(neural_network_test PROPERTIES\n",
        "    CUDA_STANDARD 17\n",
        "    CXX_STANDARD 17\n",
        ")\n",
        "\n",
        "# JSON generator executable  \n",
        "add_executable(json_generator nn_gen/json_generator.cpp)\n",
        "target_link_libraries(json_generator PRIVATE nlohmann_json::nlohmann_json)\n",
        "set_target_properties(json_generator PROPERTIES\n",
        "    CXX_STANDARD 17\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Mock Dependencies\n",
        "\n",
        "The `mock_dependencies.h` file provides compatibility with the Allen framework.\n",
        "\n",
        "### 7.1 Mock Allen Framework Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pragma once\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <fstream>\n",
        "#include <vector>\n",
        "#include <string>\n",
        "#include <memory>\n",
        "#include <nlohmann/json.hpp>\n",
        "#include <cassert>\n",
        "\n",
        "// Mock Allen namespace functions\n",
        "namespace Allen {\n",
        "    enum MemcpyKind {\n",
        "        memcpyHostToDevice = cudaMemcpyHostToDevice,\n",
        "        memcpyDeviceToHost = cudaMemcpyDeviceToHost,\n",
        "        memcpyDeviceToDevice = cudaMemcpyDeviceToDevice\n",
        "    };\n",
        "\n",
        "    inline void malloc(void** ptr, size_t size) {\n",
        "        cudaMalloc(ptr, size);\n",
        "    }\n",
        "\n",
        "    inline void memcpy(void* dst, const void* src, size_t size, MemcpyKind kind) {\n",
        "        cudaMemcpy(dst, src, size, (cudaMemcpyKind)kind);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Mock base class for MVA models\n",
        "struct MVAModelBase {\n",
        "    std::string m_name, m_path;\n",
        "    MVAModelBase(std::string name, std::string path) : m_name(name), m_path(path) {}\n",
        "    virtual void readData(std::string parameters_path) = 0;\n",
        "    virtual ~MVAModelBase() = default;\n",
        "};"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. JSON Model Format\n",
        "\n",
        "The neural network parameters are stored in JSON format for easy configuration and testing.\n",
        "\n",
        "### 8.1 JSON Schema\n",
        "\n",
        "The model file contains the following fields:\n",
        "\n",
        "| Field | Type | Description |\n",
        "|-------|------|-------------|\n",
        "| `num_input` | integer | Number of input features |\n",
        "| `num_node` | integer | Number of hidden layer neurons |\n",
        "| `mean` | array[float] | Input normalization means |\n",
        "| `std` | array[float] | Input normalization standard deviations |\n",
        "| `weights1` | array[array[float]] | Hidden layer weights (num_node × num_input) |\n",
        "| `bias1` | array[float] | Hidden layer biases |\n",
        "| `weights2` | array[float] | Output layer weights |\n",
        "| `bias2` | float | Output layer bias |\n",
        "\n",
        "### 8.2 Example JSON Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{\n",
        "    \"num_input\": 4,\n",
        "    \"num_node\": 8,\n",
        "    \"mean\": [0.5, 1.2, -0.3, 2.1],\n",
        "    \"std\": [1.0, 0.8, 1.5, 0.9],\n",
        "    \"weights1\": [\n",
        "        [0.234, -0.567, 0.891, 0.123],\n",
        "        [-0.456, 0.789, 0.345, -0.678],\n",
        "        [0.123, -0.234, 0.567, -0.890],\n",
        "        [0.678, 0.345, -0.123, 0.456],\n",
        "        [-0.789, 0.234, 0.567, -0.345],\n",
        "        [0.890, -0.123, 0.456, 0.678],\n",
        "        [-0.345, 0.678, -0.789, 0.234],\n",
        "        [0.456, -0.890, 0.123, -0.567]\n",
        "    ],\n",
        "    \"bias1\": [0.1, -0.2, 0.3, -0.4, 0.5, -0.6, 0.7, -0.8],\n",
        "    \"weights2\": [0.8, -0.6, 0.4, -0.2, 0.9, -0.7, 0.5, -0.3],\n",
        "    \"bias2\": 0.15\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Compilation and Usage\n",
        "\n",
        "### 9.1 Requirements\n",
        "\n",
        "- **NVIDIA GPU** with CUDA support\n",
        "- **CUDA Toolkit** (tested with CUDA 12.x)  \n",
        "- **C++17** compatible compiler\n",
        "- **CMake** (3.18+)\n",
        "- **nlohmann-json** library (system-wide installation)\n",
        "\n",
        "### 9.2 GPU Architecture Support\n",
        "\n",
        "The CMakeLists.txt can be configured for different GPU architectures:\n",
        "\n",
        "| Architecture | GPU Series | Compute Capability |\n",
        "|--------------|-------------|-------------------|\n",
        "| `sm_60` | GTX 10 series | 6.0 |\n",
        "| `sm_70` | Titan V, GTX 16 series | 7.0 |\n",
        "| `sm_75` | RTX 20 series | 7.5 (default) |\n",
        "| `sm_86` | RTX 30 series | 8.6 |\n",
        "| `sm_89` | RTX 40 series | 8.9 |\n",
        "\n",
        "### 9.3 Build Commands\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create build directory\n",
        "!mkdir build\n",
        "!cd build\n",
        "\n",
        "# Configure project\n",
        "!cmake ..\n",
        "\n",
        "# Compile executables\n",
        "!make\n",
        "\n",
        "# This creates two executables:\n",
        "# - json_generator: Creates random model parameters\n",
        "# - neural_network_test: Runs neural network evaluation tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9.4 Usage Examples\n",
        "\n",
        "#### Generate a Random Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate model with 4 inputs, 8 hidden nodes\n",
        "./json_generator 4 8 ../test_model.json\n",
        "\n",
        "# Generate model with custom parameters\n",
        "./json_generator 6 16 ../my_custom_model.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run Neural Network Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with generated model\n",
        "./neural_network_test ../test_model.json\n",
        "\n",
        "# Expected output:\n",
        "# CUDA Neural Network Demo\n",
        "# ========================\n",
        "# Using CUDA device: GeForce RTX 3080\n",
        "# Compute capability: 8.6\n",
        "# \n",
        "# === Neural Network Evaluation Test ===\n",
        "# Network configuration:\n",
        "# - Input size: 4\n",
        "# - Hidden nodes: 8\n",
        "# - Number of test cases: 10\n",
        "# ✓ Model loaded successfully\n",
        "# \n",
        "# Generating random test inputs...\n",
        "# Launching CUDA kernel...\n",
        "# Grid size: 1, Block size: 256\n",
        "# \n",
        "# === Test Results ===\n",
        "# Test  1: Input [-0.527618, -0.339161,  1.488258, -0.412800] -> Output: 0.947760\n",
        "# Test  2: Input [ 0.694293,  1.286170,  1.175678, -0.213452] -> Output: 0.694606\n",
        "# ...\n",
        "# \n",
        "# === Validation ===\n",
        "# ✓ All outputs are in valid range [0, 1] (sigmoid activation)\n",
        "# Output statistics:\n",
        "# - Min: 0.382523\n",
        "# - Max: 0.952799  \n",
        "# - Average: 0.793204\n",
        "# \n",
        "# ✓ Test completed successfully!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Performance Analysis\n",
        "\n",
        "### 10.1 CUDA Optimization Techniques\n",
        "\n",
        "The implementation uses several optimization strategies:\n",
        "\n",
        "#### Loop Unrolling\n",
        "```cuda\n",
        "#if (defined(TARGET_DEVICE_CUDA) && defined(__CUDACC__))\n",
        "#pragma unroll\n",
        "#endif\n",
        "```\n",
        "- Reduces loop overhead\n",
        "- Enables better instruction-level parallelism\n",
        "- Compile-time optimization for known loop bounds\n",
        "\n",
        "#### Template-based Design\n",
        "- Compile-time configuration of network dimensions\n",
        "- Eliminates runtime branching\n",
        "- Enables aggressive compiler optimizations\n",
        "\n",
        "#### Fast Math Operations\n",
        "- Uses `__expf()` for single-precision exponential\n",
        "- Optimized for GPU execution\n",
        "- Leverages CUDA intrinsic functions\n",
        "\n",
        "#### Memory Access Patterns\n",
        "- Coalesced memory access for input data\n",
        "- Local arrays for temporary computations\n",
        "- Efficient GPU memory utilization\n",
        "\n",
        "### 10.2 Performance Characteristics\n",
        "\n",
        "| Aspect | Benefit |\n",
        "|--------|---------|\n",
        "| **Parallel Evaluation** | Process multiple inputs simultaneously |\n",
        "| **Template Specialization** | Zero runtime overhead for network configuration |\n",
        "| **CUDA Intrinsics** | Hardware-accelerated mathematical operations |\n",
        "| **Memory Coalescing** | Optimal memory bandwidth utilization |\n",
        "\n",
        "### 10.3 Scalability\n",
        "\n",
        "The implementation scales well with:\n",
        "- Number of concurrent test cases\n",
        "- GPU compute capability\n",
        "- Memory bandwidth\n",
        "- Number of CUDA cores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Allen Framework Background\n",
        "\n",
        "### 11.1 About Allen\n",
        "\n",
        "Allen is a revolutionary GPU-based trigger system developed for the LHCb experiment at CERN. This neural network demo is adapted from Allen's production codebase.\n",
        "\n",
        "#### Key Facts about Allen:\n",
        "- **First complete high-throughput GPU trigger** for a High Energy Physics experiment\n",
        "- **Processes 40 Tbit/s** data rate from the upgraded LHCb detector  \n",
        "- **Reduces data rate** by factor of 30-60 in real-time\n",
        "- **Implemented in ~500 GPU cards** for production operation\n",
        "- **Operates at full LHC collision rate** of 30-40 MHz\n",
        "\n",
        "### 11.2 Technical Achievements\n",
        "\n",
        "#### Performance Metrics\n",
        "- **Throughput**: Processes millions of collision events per second\n",
        "- **Latency**: Real-time decision making within microseconds\n",
        "- **Efficiency**: Linear scaling with GPU computational power\n",
        "- **Reliability**: Production-ready for continuous operation\n",
        "\n",
        "#### Algorithm Portfolio\n",
        "Allen implements numerous pattern recognition algorithms:\n",
        "- **Charged particle tracking** through silicon detectors\n",
        "- **Primary vertex reconstruction** from collision points\n",
        "- **Particle identification** (hadrons vs muons)\n",
        "- **Displaced vertex finding** for long-lived particle decays\n",
        "\n",
        "### 11.3 Innovation Impact\n",
        "\n",
        "Allen represents a paradigm shift in high-energy physics computing:\n",
        "- **GPU-first architecture** for trigger systems\n",
        "- **Template-based programming** for compile-time optimization  \n",
        "- **Heterogeneous computing** leveraging CPU and GPU strengths\n",
        "- **Open-source framework** enabling broad community adoption\n",
        "\n",
        "### 11.4 Publications and Recognition\n",
        "\n",
        "- Published in **Journal of Instrumentation** (2020)\n",
        "- **CERN openlab** collaboration project\n",
        "- Featured in **NVIDIA** GPU computing showcases\n",
        "- **Apache 2.0 license** for community access\n",
        "\n",
        "This neural network demo preserves Allen's design principles while providing a simplified, educational implementation suitable for learning CUDA neural network programming.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Complete Example Workflow\n",
        "\n",
        "### 12.1 Step-by-Step Tutorial\n",
        "\n",
        "Let's walk through a complete example from model generation to evaluation:\n",
        "\n",
        "#### Step 1: Environment Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install dependencies (Ubuntu/Debian)\n",
        "sudo apt update\n",
        "sudo apt install build-essential cmake nvidia-cuda-toolkit\n",
        "sudo apt install nlohmann-json3-dev\n",
        "\n",
        "# Fedora/Red Hat instructions\n",
        "sudo dnf groupinstall \"Development Tools\"\n",
        "sudo dnf install cmake cuda-toolkit\n",
        "sudo dnf install nlohmann-json-devel\n",
        "\n",
        "# Verify CUDA installation\n",
        "nvcc --version\n",
        "nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for this tutorial all the dependencies are included in the binder environment except following\n",
        "# run this from command line to install nlohmann_json, not from the cell \n",
        "!conda install -c conda-forge nlohmann_json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 2: Build the Project\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create build directory\n",
        "mkdir build && cd build\n",
        "\n",
        "# Configure with CMake\n",
        "cmake .. -DCMAKE_BUILD_TYPE=Release\n",
        "\n",
        "# Compile (adjust -j flag based on available CPU cores)\n",
        "make -j4\n",
        "\n",
        "# Verify executables were created\n",
        "ls -la json_generator neural_network_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 3: Generate Model Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate a model with 4 inputs and 8 hidden neurons\n",
        "./json_generator 4 8 ../demo_model.json\n",
        "\n",
        "# Check the generated file\n",
        "cat ../demo_model.json | head -20\n",
        "\n",
        "# Generate models with different architectures\n",
        "./json_generator 6 12 ../larger_model.json\n",
        "./json_generator 2 4 ../smaller_model.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 4: Run Neural Network Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the demo model\n",
        "./neural_network_test ../demo_model.json\n",
        "\n",
        "# Test different models\n",
        "./neural_network_test ../larger_model.json\n",
        "./neural_network_test ../smaller_model.json\n",
        "\n",
        "# Save output to file for analysis\n",
        "./neural_network_test ../demo_model.json > results.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 12.2 Python Integration Example\n",
        "\n",
        "You can integrate this CUDA implementation with Python for data analysis:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_and_test_model(num_input, num_hidden, model_name):\n",
        "    \"\"\"Generate a model and run tests, return results\"\"\"\n",
        "\n",
        "    # Generate model\n",
        "    subprocess.run([\n",
        "        './json_generator', \n",
        "        str(num_input), \n",
        "        str(num_hidden), \n",
        "        f'../models/{model_name}.json'\n",
        "    ])\n",
        "\n",
        "    # Run test and capture output  \n",
        "    result = subprocess.run([\n",
        "        './neural_network_test', \n",
        "        f'../models/{model_name}.json'\n",
        "    ], capture_output=True, text=True)\n",
        "\n",
        "    return result.stdout\n",
        "\n",
        "def analyze_model_performance():\n",
        "    \"\"\"Analyze performance across different model sizes\"\"\"\n",
        "\n",
        "    configurations = [\n",
        "        (2, 4, \"small\"),\n",
        "        (4, 8, \"medium\"), \n",
        "        (8, 16, \"large\")\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "    for num_input, num_hidden, name in configurations:\n",
        "        output = generate_and_test_model(num_input, num_hidden, name)\n",
        "\n",
        "        # Parse output statistics (simplified parsing)\n",
        "        # In practice, you'd use more robust parsing\n",
        "        lines = output.split('\\n')\n",
        "        for line in lines:\n",
        "            if 'Average:' in line:\n",
        "                avg_output = float(line.split(':')[-1].strip())\n",
        "                results[name] = {\n",
        "                    'config': (num_input, num_hidden),\n",
        "                    'avg_output': avg_output\n",
        "                }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example usage\n",
        "results = analyze_model_performance()\n",
        "print(\"Model Performance Analysis:\")\n",
        "for name, data in results.items():\n",
        "    config = data['config'] \n",
        "    avg = data['avg_output']\n",
        "    print(f\"{name}: {config[0]}x{config[1]} -> avg output: {avg:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 12.3 Performance Benchmarking\n",
        "\n",
        "For production deployments, consider benchmarking different configurations:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Benchmark script example\n",
        "for input_size in 2 4 6 8; do\n",
        "    for hidden_size in 4 8 16 32; do\n",
        "        echo \"Testing ${input_size}x${hidden_size} configuration...\"\n",
        "        ./json_generator $input_size $hidden_size test_${input_size}_${hidden_size}.json\n",
        "        time ./neural_network_test test_${input_size}_${hidden_size}.json\n",
        "        echo \"---\"\n",
        "    done\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This comprehensive tutorial has demonstrated a complete CUDA neural network implementation adapted from CERN's Allen framework. The key takeaways include:\n",
        "\n",
        "### Technical Achievements\n",
        "- **Template-based design** enabling compile-time optimizations\n",
        "- **GPU memory management** with efficient CUDA memory operations  \n",
        "- **Optimized kernels** using loop unrolling and fast math\n",
        "- **JSON-based configuration** for flexible model parameters\n",
        "- **Production-ready code** adapted from real LHC trigger systems\n",
        "\n",
        "### Educational Value\n",
        "- Complete CUDA neural network from scratch\n",
        "- Integration of C++, CUDA, and CMake build systems\n",
        "- Real-world application from high-energy physics\n",
        "- Performance optimization techniques\n",
        "- Memory management best practices\n",
        "\n",
        "### Extensions and Future Work\n",
        "\n",
        "This implementation can be extended in several ways:\n",
        "1. **Multi-layer networks** with arbitrary depth\n",
        "2. **Batch processing** for improved throughput\n",
        "3. **Training capabilities** with backpropagation\n",
        "4. **Different activation functions** (tanh, leaky ReLU, etc.)\n",
        "5. **Mixed-precision arithmetic** using Tensor Cores\n",
        "6. **Multi-GPU scaling** for large-scale deployments\n",
        "\n",
        "### Resources for Further Learning\n",
        "\n",
        "- **Allen Documentation**: https://allen-doc.docs.cern.ch\n",
        "- **NVIDIA CUDA Toolkit**: https://developer.nvidia.com/cuda-toolkit\n",
        "- **cuDNN Library**: https://developer.nvidia.com/cudnn\n",
        "- **CUDA Programming Guide**: https://docs.nvidia.com/cuda/cuda-c-programming-guide/\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "array-oriented-programming",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
